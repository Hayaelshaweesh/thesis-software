# -*- coding: utf-8 -*-
"""train_rf_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iUmr6UpFcYuAnGEB3CT7JTUwRSoBk8hU
"""

import pandas as pd
import numpy as np
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OrdinalEncoder
from sklearn.model_selection import train_test_split

# ===== 1. Load meta-dataset =====
data_path = "data/meta_dataset_sample.csv"
data = pd.read_csv(data_path)

# ===== 2. Separate features and target =====
target_column = "Technique Name"
X = data.drop(columns=[target_column])
y = data[target_column]

# ===== 3. Identify categorical and numeric columns =====
cat_cols = X.select_dtypes(include='object').columns.tolist()
num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

# ===== 4. Clean numeric data =====
X[num_cols] = X[num_cols].replace([np.inf, -np.inf], np.nan)
X[num_cols] = X[num_cols].fillna(X[num_cols].mean())

# ===== 5. Encode categorical columns =====
encoder = None
if len(cat_cols) > 0:
    encoder = OrdinalEncoder()
    X[cat_cols] = encoder.fit_transform(X[cat_cols])

# ===== 6. Scale numeric columns =====
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# ===== 7. Train/test split (optional) =====
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ===== 8. Train RandomForestClassifier =====
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# ===== 9. Save artifacts =====
import os
os.makedirs("models", exist_ok=True)

with open("models/SHF_MVI_model.pkl", "wb") as f:
    pickle.dump(model, f)


with open("models/encoder.pkl", "wb") as f:
    pickle.dump(encoder, f)

with open("models/scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)

with open("models/column_info.pkl", "wb") as f:
    pickle.dump({"cat_cols": cat_cols, "num_cols": num_cols}, f)

print("Training complete. Model, encoder, scaler, and column info saved!")